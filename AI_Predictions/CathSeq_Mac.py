import numpy as np
import tensorflow as tf
import pandas as pd
from tqdm import tqdm
import os
from cv2 import imread, createCLAHE
import cv2
from glob import glob
import matplotlib.pyplot as plt

from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras import backend as keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler

from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau


from IPython.display import clear_output
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
# image_path = os.path.join("./images/")
# mask_path = os.path.join("./masks/")





def getData(X_shape, imagePath, maskPath):
    im_array = []
    mask_array = []
    
    training_files = set(os.listdir(imagePath))
    print("The number of file is ",len(imagePath))
    
    
    for i in tqdm(training_files):
        im = cv2.resize(cv2.imread(os.path.join(imagePath,i)),(X_shape,X_shape))[:,:,0]
        mask = cv2.resize(cv2.imread(os.path.join(maskPath,i.replace('.jpg','_mask.jpg'))),(X_shape,X_shape))[:,:,0]

        im_array.append(im)
        mask_array.append(mask)

    return im_array,mask_array

#perform sanity check

def plotMask(X,y):
    sample = []
    
    for i in range(6):
        left = X[i]
        right = y[i]
        combined = np.hstack((left,right))
        sample.append(combined)
        
        
    for i in range(0,6,3):

        plt.figure(figsize=(25,10))
        
        plt.subplot(2,3,1+i)
        plt.imshow(sample[i])
        
        plt.subplot(2,3,2+i)
        plt.imshow(sample[i+1])
        
        
        plt.subplot(2,3,3+i)
        plt.imshow(sample[i+2])
        
        plt.show()
        
# Load training and testing data. dim is 512
def loadFullData(imagePath, maskPath, dim = 512):
    X_train,y_train = getData(dim, imagePath, maskPath)

    print("training set")
    #plotMask(X_train,y_train)

    X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)
    y_train = np.array(y_train).reshape(len(y_train),dim,dim,1)
    assert X_train.shape == y_train.shape
    images = X_train
    mask  = y_train
    return images, mask




def dice_coef(y_true, y_pred):
    y_true_f = keras.flatten(y_true)
    y_pred_f = keras.flatten(y_pred)
    intersection = keras.sum(y_true_f * y_pred_f)
    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)

def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

def unet(input_size=(256,256,1)):
    inputs = Input(input_size)
    
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)
    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)

    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)

    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)

    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)

    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)

    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)

    return Model(inputs=[inputs], outputs=[conv10])
    
def loadModel():
    model = unet(input_size=(512,512,1))
    model.compile(optimizer=Adam(learning_rate=1e-5), loss=dice_coef_loss,
                    metrics=[dice_coef, 'binary_accuracy'])
    model.summary()
    
    return model

def trainModel(model, images, mask):

    # Callbacks, Early Stopping and Reduced LR

    weight_path="{}.weights.h5".format('cxr_reg')

    checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,
                                save_best_only=True, mode='min', save_weights_only = True)

    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5,
                                    patience=3,
                                    verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)
    early = EarlyStopping(monitor="val_loss",
                        mode="min",
                        patience=15) # probably needs to be more patient, but kaggle time is limited
    callbacks_list = [checkpoint, early, reduceLROnPlat]

    train_vol, validation_vol, train_seg, validation_seg = train_test_split((images-127.0)/127.0,
                                                                (mask>127).astype(np.float32),
                                                                test_size = 0.1,random_state = 2018)

    loss_history = model.fit(x = train_vol,
                        y = train_seg,
                            batch_size = 16,
                    epochs = 100,
                    validation_data =(validation_vol,validation_seg) ,
                    callbacks=callbacks_list)
                    
    # Save the model probably all-in-one model
    model.save('saved_model')

# convert the history.history dict to a pandas DataFrame:
    hist_df = pd.DataFrame(loss_history.history)
    # save to csv:
    hist_csv_file = './history.csv'
    with open(hist_csv_file, mode='w') as f:
        hist_df.to_csv(f)
            
    plt.plot(loss_history.history['loss'])
    plt.plot(loss_history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.show()
    
if(__name__ == "__main__"):
    images, mask = loadFullData(imagePath="AI_Predictions/Images", maskPath="AI_Predictions/Masks")
    model = loadModel()
    trainModel(model, images, mask)
